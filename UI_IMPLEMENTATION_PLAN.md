# NEXUS UI Implementation Plan â€” Missing Features

> **Goal**: Emphasize ease of interfacing with AI. Every interaction should feel like talking to a
> brilliant Chief of Staff who already knows the org â€” not like filling out forms.
>
> **Judge criteria we're targeting**: "Voice and low-friction interaction, minimal typing and clicks"
> and "visualizing agentic AI reasoning and communication flows."

---

## Design Philosophy

The challenge PDF says: *"Not a chatbot. Not a feed. But a new intelligence layer."*

Every new UI element should reinforce this. The AI shouldn't feel like a tool you operate â€”
it should feel like a colleague who proactively surfaces what matters. Three principles:

1. **Zero-click insights** â€” The AI presents information before you ask
2. **One-action commands** â€” Any interaction is at most one click or one sentence
3. **Visible reasoning** â€” When the AI works, you see *how* it thinks (agents running, graph traversal, routing logic)

---

## Priority Map

| Priority | Feature | Judge Criteria Hit | Time Est |
|----------|---------|-------------------|----------|
| **P0** | Command Bar (Cmd+K) | UX & Interaction, Demo Quality | 2h |
| **P0** | Voice Input | UX & Interaction (explicitly requested) | 1h |
| **P0** | Briefing View | Communication Intelligence, Demo Quality | 2h |
| **P1** | Immune Scan Visualization | Deconfliction, Visualizing AI Reasoning | 1.5h |
| **P1** | People & Workforce View | Knowledge Graph, Stakeholder Map | 2h |
| **P2** | Notification Center | Communication Intelligence, Routing | 1h |
| **P2** | Task Graph View | Creativity, Moonshot Thinking | 1.5h |
| **P2** | LLM Usage Overlay | Demo polish | 30m |

---

## P0 â€” Must Build

### 1. Command Bar (Cmd+K Spotlight)

**Why**: This is the single highest-impact addition. It unifies every AI interaction into one
low-friction entry point. Instead of navigating to different views and clicking buttons, the user
presses Cmd+K and talks to NEXUS in natural language. NEXUS figures out what to do.

**Route**: Global overlay (no route â€” appears on any page via Cmd+K or clicking the search icon)

**File**: `nexus-ui/src/components/CommandBar.tsx`

**Behavior**:
```
User presses Cmd+K â†’ modal overlay appears with input field + mic button
User types or speaks: "What changed today?"
  â†’ NEXUS classifies intent â†’ routes to /api/ask â†’ streams response inline
User types: "Run an immune scan"
  â†’ NEXUS routes to /api/immune/scan â†’ shows agent progress inline
User types: "Brief me as Sarah Chen"
  â†’ NEXUS routes to /api/briefing/generate â†’ streams briefing
User types: "Show me the pricing contradiction"
  â†’ NEXUS routes to /alerts with filter â†’ navigates there
User types: "Who's overloaded right now?"
  â†’ NEXUS routes to /api/workers/status â†’ shows inline summary
```

**Layout**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”  Ask NEXUS anything...              [ğŸ¤] [âŒ˜K] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  Recent:                                           â”‚
â”‚    "What changed today?"                           â”‚
â”‚    "Run immune scan"                               â”‚
â”‚    "Brief me as David Kim"                         â”‚
â”‚                                                    â”‚
â”‚  Quick Actions:                                    â”‚
â”‚    âš¡ Morning Briefing    ğŸ›¡ï¸ Run Immune Scan       â”‚
â”‚    ğŸ‘¥ Workforce Status    ğŸ“Š What Changed?         â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

When a response streams in, the modal expands to show it:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”  "what changed today?"              [ğŸ¤] [âŒ˜K] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                    â”‚
â”‚  ğŸ¤– NEXUS is thinking...                           â”‚
â”‚  â”Œâ”€ Routing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Intent: organizational_query               â”‚   â”‚
â”‚  â”‚ Agent: RAG + Context Builder               â”‚   â”‚
â”‚  â”‚ Sources: 87 nodes, 7 alerts, 5 decisions   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                    â”‚
â”‚  Three things changed in the last 24 hours:        â”‚
â”‚                                                    â”‚
â”‚  1. âš ï¸ Pricing contradiction between Sarah Chen    â”‚
â”‚     and Nova-Sales ($20 vs $15 premium tier)       â”‚
â”‚     â†’ [View Alert] [Trace Decision Chain]          â”‚
â”‚                                                    â”‚
â”‚  2. ğŸ“‰ Atlas-Code's REST v3 API doc is stale       â”‚
â”‚     (team switched to GraphQL 3 weeks ago)         â”‚
â”‚     â†’ [View on Graph] [Mark as Resolved]           â”‚
â”‚                                                    â”‚
â”‚  3. ğŸ”´ Catherine Moore at 88% cognitive load       â”‚
â”‚     (4 active commitments, 2 pending decisions)    â”‚
â”‚     â†’ [View Person] [Redistribute Tasks]           â”‚
â”‚                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key implementation details**:
- Use `/api/ask` with `stream: true` for natural language queries
- Show a "Routing" box that reveals which backend path NEXUS chose (visible AI reasoning)
- Quick Actions are hardcoded shortcuts that call specific endpoints
- Response items have inline action buttons that navigate to the relevant view
- Escape or click-outside closes the modal
- History persisted in localStorage

**Backend integration**:
- Natural language queries â†’ `POST /api/ask` (existing, with streaming)
- "Run immune scan" â†’ `POST /api/immune/scan`
- "Brief me as [person]" â†’ `POST /api/briefing/generate`
- "Workforce status" â†’ `GET /api/workers/status`
- Intent classification happens client-side via keyword matching (fast) with LLM fallback

---

### 2. Voice Input

**Why**: The challenge PDF explicitly lists "Voice and low-friction interaction" as evaluation
criteria. Adding a mic button demonstrates multimodal input with minimal effort.

**File**: `nexus-ui/src/hooks/useVoiceInput.ts`

**Integration points**:
- Mic button in Command Bar
- Mic button in Ask NEXUS view (existing)
- Mic button in InfoDrop widget

**Implementation**:
```typescript
// useVoiceInput.ts â€” uses Web Speech API (built into Chrome/Edge)
// Returns: { isListening, transcript, startListening, stopListening }
// On transcript finalize â†’ auto-submit to the active input
```

**UX flow**:
1. User clicks mic icon (or holds spacebar in Command Bar)
2. Pulsing red indicator shows recording is active
3. Real-time transcript appears in the input field
4. On silence detection (1.5s) â†’ auto-submit
5. Response streams back as normal

**Visual indicator**: When voice is active, the Command Bar input gets a pulsing red ring
and the mic icon animates. The transcript appears in real-time as the user speaks.

**Demo script moment**: Open Cmd+K â†’ click mic â†’ say "What changed today?" â†’ response
streams in. Total interaction: 1 click + 3 words spoken. This is the "superhuman" moment.

---

### 3. Briefing View

**Why**: Directly maps to the challenge scenario: *"A founder asks: What changed today? â†’ the AI
generates a visual map of updates."* This is the AI Chief of Staff's killer feature.

**Route**: `/briefing`

**File**: `nexus-ui/src/views/BriefingView.tsx`

**Sidebar nav**: Add a new icon (ğŸ“‹ `Briefing` with `FileText` from lucide-react)

**Layout**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Good morning. Select your identity:                      â”‚
â”‚                                                           â”‚
â”‚  [Sarah Chen - VP Sales]  [David Kim - CTO]               â”‚
â”‚  [Maria Santos - COO]     [James Wright - Head of Eng]    â”‚
â”‚  [Catherine Moore - PM]   [Custom person ID...]           â”‚
â”‚                                                           â”‚
â”‚  â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€   â”‚
â”‚                                                           â”‚
â”‚  â˜€ï¸ DAILY BRIEFING â€” Sarah Chen                           â”‚
â”‚  Generated by NEXUS at 9:02 AM                            â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€ What Needs Your Attention â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ğŸ”´ Pricing contradiction with Nova-Sales ($20 v $15) â”‚ â”‚
â”‚  â”‚    You set $20 on Jan 28. Nova-Sales quotes $15.     â”‚ â”‚
â”‚  â”‚    â†’ [Resolve This] [See Decision Chain]             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€ What Changed Since Yesterday â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Atlas-Code switched from REST v3 to GraphQL        â”‚ â”‚
â”‚  â”‚ â€¢ New commitment: APAC launch moved to Q3            â”‚ â”‚
â”‚  â”‚ â€¢ 2 new edges: David Kim â†” Payments team             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€ Your Open Decisions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 1. Premium tier pricing (BLOCKING â€” 3 teams)         â”‚ â”‚
â”‚  â”‚ 2. Q2 hiring plan (due Feb 15)                       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€ Your Cognitive Load â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 65%  (3 commitments, 2 decisions)         â”‚ â”‚
â”‚  â”‚ Compared to org avg: 52%                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€ People Who Need You â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Catherine Moore (PM) â€” waiting on pricing decision   â”‚ â”‚
â”‚  â”‚ James Wright (Eng) â€” blocked on API spec approval    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key implementation details**:
- Person selector at top (pre-populated from graph nodes where `type === 'person'`)
- Clicking a person calls `POST /api/briefing/generate { person_id, stream: true }`
- Briefing streams in section by section with typewriter effect
- Each section is a card with inline action buttons
- The "Cognitive Load" section uses the existing `CognitiveLoadBar` component
- "People Who Need You" section shows pending notifications from `/api/routing/pending?person_id=X`
- Fallback: If LLM unavailable, build briefing client-side from graph data (filter nodes/edges/alerts relevant to the person)

**Static fallback for demo** (no LLM needed):
- Read the person's node from graph
- Find all edges connected to them
- Find all alerts where they're in `affected_node_ids`
- Find all decisions where they're the `source_id`
- Render these as the briefing sections

---

## P1 â€” Should Build

### 4. Immune Scan Visualization (enhance existing AlertsView)

**Why**: The judges specifically look for "Deconfliction & Critique" and "visualizing agentic AI
reasoning." Running 6 parallel agents and showing their status live is the most direct way to
demonstrate multi-agent AI reasoning.

**File**: Modify existing `nexus-ui/src/views/AlertsView.tsx`

**Addition**: A "Run Immune Scan" button at the top + an agent status panel

**Layout addition at top of AlertsView**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ›¡ï¸ NEXUS Immune System                    [Run Scan â–¶]  â”‚
â”‚                                                           â”‚
â”‚  When scan is running:                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Scanning organization...                            â”‚  â”‚
â”‚  â”‚                                                      â”‚  â”‚
â”‚  â”‚  âœ… Contradiction Agent    â€” 2 findings              â”‚  â”‚
â”‚  â”‚  âœ… Staleness Agent        â€” 1 finding               â”‚  â”‚
â”‚  â”‚  â³ Silo Detection Agent   â€” analyzing...            â”‚  â”‚
â”‚  â”‚  â³ Overload Agent         â€” analyzing...            â”‚  â”‚
â”‚  â”‚  â¬œ Coordination Agent     â€” queued                  â”‚  â”‚
â”‚  â”‚  â¬œ Drift Agent            â€” queued                  â”‚  â”‚
â”‚  â”‚                                                      â”‚  â”‚
â”‚  â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  4/6 agents complete           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                           â”‚
â”‚  (existing alert cards below...)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key implementation details**:
- "Run Scan" calls `POST /api/immune/scan` (returns all 6 agent results)
- While waiting, show progress animation with 6 agent slots
- Since the API returns all at once, simulate sequential completion for visual drama:
  - Show agents completing one by one with 300ms stagger
  - Each agent slot transitions from â¬œ â†’ â³ â†’ âœ… with finding count
- New alerts from scan results get prepended to the alert list with a "NEW" badge
- "Scan History" link calls `GET /api/immune/history`

**Alternative**: Run each agent individually via `POST /api/immune/scan/{agent_name}` for real
parallel execution with live updates per agent. More impressive but requires 6 parallel API calls.

---

### 5. People & Workforce View

**Why**: Maps to "Knowledge Graph & Stakeholder Map" criteria. Shows every person and AI agent
in the org with their cognitive load, assignments, and relationships. This is where the
"Who needs to know this?" question gets answered visually.

**Route**: `/people`

**File**: `nexus-ui/src/views/PeopleView.tsx`

**Sidebar nav**: Add icon (ğŸ‘¥ `Users` from lucide-react)

**Layout**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  People & Agents                          [Analyze â–¶]     â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€ Filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ [All] [People] [AI Agents] â”‚ [By Division â–¼]     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€ Attention Required â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ ğŸ”´ Catherine Moore â€” 88% cognitive load (overloaded)  â”‚â”‚
â”‚  â”‚ ğŸŸ¡ James Wright â€” 2 blocked decisions                 â”‚â”‚
â”‚  â”‚ ğŸŸ¡ Nova-Sales â€” trust level: review_required          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€ North America Division â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                                                       â”‚â”‚
â”‚  â”‚  Sarah Chen          David Kim         Catherine Mooreâ”‚â”‚
â”‚  â”‚  VP Sales, NA        CTO, HQ           PM, NA        â”‚â”‚
â”‚  â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 65%        â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 45%      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 88% â”‚â”‚
â”‚  â”‚  2 decisions         1 decision        4 commitments  â”‚â”‚
â”‚  â”‚  ğŸŸ¢ healthy          ğŸŸ¢ healthy        ğŸ”´ overloaded  â”‚â”‚
â”‚  â”‚                                                       â”‚â”‚
â”‚  â”‚  ğŸ¤– Nova-Sales       ğŸ¤– Atlas-Code                    â”‚â”‚
â”‚  â”‚  Sales AI Agent      Coding AI Agent                  â”‚â”‚
â”‚  â”‚  â¬¡ supervised        â¬¡ autonomous                    â”‚â”‚
â”‚  â”‚  3 active tasks      2 active tasks                   â”‚â”‚
â”‚  â”‚  ğŸŸ¡ review_required  ğŸŸ¢ trusted                       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                           â”‚
â”‚  Clicking a person card expands to show:                  â”‚
â”‚  â”Œâ”€ Sarah Chen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Role: VP Sales, North America                         â”‚â”‚
â”‚  â”‚ Cognitive Load: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 65%                          â”‚â”‚
â”‚  â”‚ Active Commitments: 3                                 â”‚â”‚
â”‚  â”‚ Pending Decisions: 2                                  â”‚â”‚
â”‚  â”‚ Connected to: 8 people, 2 AI agents, 4 teams         â”‚â”‚
â”‚  â”‚ Open Alerts: 1 (pricing contradiction)                â”‚â”‚
â”‚  â”‚                                                       â”‚â”‚
â”‚  â”‚ [Generate Briefing] [View on Graph] [See Assignments] â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key implementation details**:
- Load all nodes where `type === 'person'` or `type === 'agent'` from `/api/graph`
- "Attention Required" section auto-computes: cognitive_load > 0.8, nodes with health=red/orange
- "Analyze" button calls `POST /api/workers/analyze` â†’ shows AI-generated insights
- Group by division (from node.division field)
- Person cards show: name, role (from extras), cognitive_load bar, commitment count, health dot
- Agent cards show: name, agent_type, trust_level (hexagon icon for agents), active_tasks count
- Clicking a card expands inline (like AlertsView)
- "Generate Briefing" navigates to `/briefing?person=X`
- "View on Graph" navigates to `/pulse?highlight=X`

**Backend integration**:
- Person/agent data: from `GET /api/graph` (filter nodes)
- Worker analysis: `POST /api/workers/analyze`
- Individual assignments: `GET /api/workers/{id}/assignments`

---

## P2 â€” Nice to Have

### 6. Notification Center (Slide-out Panel)

**Why**: Demonstrates intelligent routing â€” "NEXUS decided you need to see this." Shows the AI
acting proactively rather than reactively.

**File**: `nexus-ui/src/components/NotificationPanel.tsx`

**Trigger**: Bell icon in TopBar with unread count badge

**Layout** (slides in from right):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“¬ Routed to You          [Ã—] â”‚
â”‚                                 â”‚
â”‚  NEXUS determined these need    â”‚
â”‚  your attention:                â”‚
â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ âš¡ HIGH PRIORITY          â”‚   â”‚
â”‚  â”‚ Pricing contradiction    â”‚   â”‚
â”‚  â”‚ affects your Q2 forecast â”‚   â”‚
â”‚  â”‚ Source: Immune System    â”‚   â”‚
â”‚  â”‚ [Acknowledge] [View]    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ğŸ“‹ MEDIUM                â”‚   â”‚
â”‚  â”‚ Atlas-Code team switched â”‚   â”‚
â”‚  â”‚ to GraphQL (affects docs)â”‚   â”‚
â”‚  â”‚ [Acknowledge] [View]    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Backend**: `GET /api/routing/pending?person_id=X`, `POST /api/routing/acknowledge`

---

### 7. Task Graph View

**Why**: Shows organizational task dependencies and critical path â€” demonstrates "the AI
understands dependencies" from the challenge.

**Route**: `/tasks`

**File**: `nexus-ui/src/views/TasksView.tsx`

**Layout**: A DAG visualization (could use react-flow or a simple vertical timeline) showing
tasks with dependencies, owners, and a highlighted critical path.

**Backend**: `POST /api/tasks/generate`, `GET /api/tasks/current`, `GET /api/tasks/critical-path`

---

### 8. LLM Usage Overlay

**Why**: Light polish â€” shows token usage and cost transparency in the TopBar. Demonstrates
awareness of AI costs and resource management.

**File**: Modify `nexus-ui/src/components/layout/TopBar.tsx`

**Addition**: Small badge showing "42 LLM calls | $0.03" from `GET /api/llm/usage`

---

## Navigation Changes

### Updated Sidebar (6 items)

```typescript
const navItems = [
  { path: '/pulse',     icon: Activity,       label: 'Pulse' },
  { path: '/briefing',  icon: FileText,       label: 'Briefing' },
  { path: '/alerts',    icon: AlertTriangle,  label: 'Alerts' },
  { path: '/people',    icon: Users,          label: 'People' },
  { path: '/ask',       icon: MessageSquare,  label: 'Ask NEXUS' },
  { path: '/decisions', icon: GitBranch,      label: 'Decisions' },
]
```

### Global Command Bar Trigger
- Cmd+K (or Ctrl+K) from anywhere
- Also triggered by clicking a search icon in TopBar
- The Command Bar replaces the need to navigate to Ask NEXUS for simple queries

---

## Bugfix (Required Before Build)

**DemoView.tsx line 774**: Change `.map((s, i)` â†’ `.map((_, i)` â€” unused variable blocks
`npm run build`.

---

## Implementation Order

### Phase 1: Foundation (30 min)
1. Fix DemoView.tsx build error
2. Create `useVoiceInput.ts` hook (Web Speech API wrapper)
3. Add new routes to `App.tsx` (`/briefing`, `/people`)
4. Update `Sidebar.tsx` with new nav items

### Phase 2: Command Bar (1.5h)
1. Build `CommandBar.tsx` â€” modal overlay with input + quick actions
2. Add intent classification (keyword matching for routing)
3. Wire streaming responses from `/api/ask`
4. Add visible "Routing" reasoning box
5. Integrate `useVoiceInput` â€” mic button in command bar
6. Add Cmd+K keyboard shortcut listener in `App.tsx`

### Phase 3: Briefing View (1.5h)
1. Build `BriefingView.tsx` â€” person selector + streamed briefing sections
2. Build static fallback (construct briefing from graph data, no LLM needed)
3. Add action buttons per section (Resolve, View on Graph, etc.)
4. Add cognitive load visualization using existing `CognitiveLoadBar`

### Phase 4: Immune Scan Enhancement (1h)
1. Add "Run Scan" button + agent progress panel to `AlertsView.tsx`
2. Wire to `POST /api/immune/scan` with staggered completion animation
3. Merge new alerts into existing list with "NEW" badges

### Phase 5: People View (1.5h)
1. Build `PeopleView.tsx` â€” filter tabs + person/agent cards grouped by division
2. "Attention Required" auto-computed section at top
3. Expandable card detail with actions
4. Wire "Analyze" button to `POST /api/workers/analyze`

### Phase 6: Polish (30 min)
1. Notification bell in TopBar (if time)
2. LLM usage badge in TopBar
3. Test full demo flow end-to-end

---

## Demo Script (3 minutes)

With these additions, the demo flow becomes:

1. **Open on DemoView** (0:00-0:30) â€” "This is Meridian Technologies' organizational nervous
   system. 87 people, agents, decisions, and knowledge units. Watch how information flows."
   Click "Show Contradiction" â†’ click "What Changed Today?"

2. **Cmd+K â†’ Voice** (0:30-1:00) â€” Press Cmd+K. Click mic. Say: "What changed today?"
   NEXUS shows routing reasoning, then streams the answer. "Three things need attention."
   Click on the pricing contradiction action button â†’ navigates to Alerts.

3. **Immune Scan** (1:00-1:30) â€” On Alerts view, click "Run Scan." Watch 6 AI agents
   analyze the organization in parallel. Agents complete one by one. New alerts appear.
   "NEXUS continuously monitors for contradictions, staleness, silos, and overload."

4. **Briefing** (1:30-2:00) â€” Navigate to Briefing. Select Sarah Chen.
   Briefing streams in: attention items, changes, open decisions, cognitive load.
   "Every person gets a personalized morning briefing, generated by AI from the live
   knowledge graph."

5. **People View** (2:00-2:20) â€” Navigate to People. Point out Catherine Moore at 88%
   load. "NEXUS proactively detects overloaded team members before burnout happens."
   Click "Generate Briefing" â†’ shows her view.

6. **Pulse View** (2:20-2:50) â€” Navigate to Pulse. Show the full graph. "This is the
   living knowledge graph. Every node persists in Supabase. Changes propagate in real-time
   via WebSocket subscriptions. Drop new information..." â†’ use InfoDrop.

7. **Close** (2:50-3:00) â€” "NEXUS is the company's memory, filter, coordinator, and
   Chief of Staff. Not more communication â€” better communication."

---

## Technical Notes

### Voice Input (Web Speech API)
- Built into Chrome, Edge, Safari â€” no API key needed
- `SpeechRecognition` API provides real-time transcription
- Fallback: If browser doesn't support it, hide the mic button gracefully
- No backend changes needed â€” voice transcript becomes text input

### Command Bar Intent Classification (Client-side)
Simple keyword matching is sufficient for demo. No LLM call needed for routing:
```typescript
const INTENTS = [
  { keywords: ['scan', 'immune', 'check health'], action: 'immune_scan' },
  { keywords: ['brief', 'morning', 'what changed', 'update'], action: 'briefing' },
  { keywords: ['overload', 'workforce', 'who is', 'cognitive'], action: 'workers' },
  { keywords: ['task', 'critical path', 'schedule'], action: 'tasks' },
]
// Default: fall through to /api/ask for general natural language queries
```

### Streaming Responses
All LLM-backed endpoints already support SSE streaming. The Command Bar and Briefing View
should use the existing `streamPost()` utility from `lib/sse.ts`.

### Static Fallbacks (No LLM Required)
Every new view must work without the OpenAI API key (demo safety):
- **Briefing**: Construct from graph data (person's edges, connected alerts, decisions)
- **Immune Scan**: Return the 7 pre-seeded alerts as "scan results"
- **Worker Analysis**: Compute from node cognitive_load and active_commitments fields
- **Command Bar**: Route to cached Ask responses or static graph queries
